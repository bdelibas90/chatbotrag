from datetime import date
import os
import re

import requests
from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableSequence
from langchain_openai import ChatOpenAI
from openai import OpenAI
from pydantic import BaseModel, Field
from typing import Literal



load_dotenv()

AIRTABLE_API_KEY = os.getenv("AIRTABLE_API_KEY")
AIRTABLE_BASE_ID = os.getenv("AIRTABLE_BASE_ID")          # Ã¶rn: appOrTVQJzXgO4oNg
AIRTABLE_TABLE_NAME = os.getenv("AIRTABLE_TABLE_NAME")    # Ã¶rn: "Leads"

EMAIL_REGEX = re.compile(r"^[^@\s]+@[^@\s]+\.[^@\s]+$")

if not AIRTABLE_API_KEY or not AIRTABLE_BASE_ID or not AIRTABLE_TABLE_NAME:
    raise RuntimeError("Airtable env variables are not configured")



def is_valid_email(email: str) -> bool:
    if not email:
        return False
    return EMAIL_REGEX.match(email.strip()) is not None




# -----------------------------
# OpenAI client
# -----------------------------
client = OpenAI()

# -----------------------------
# Your vectorstore ID
# -----------------------------
VECTOR_STORE_ID = "vs_68e13ee74bc88191becbd2061ca7de01"   # <-- kendi gerÃ§ek ID'ni koy

# -----------------------------
# Basit IP bazlÄ± rate limiting (gÃ¼nlÃ¼k)
# -----------------------------
WEBSEARCH_DAILY_LIMIT = 3   # keloid dÄ±ÅŸÄ± / websearch sorularÄ±
TOTAL_DAILY_LIMIT = 15      # toplam cevap limiti

# ip_stats[ip] = {"total": int, "websearch": int, "date": date}
ip_stats: dict[str, dict] = {}


def _get_ip(request: Request) -> str:
    """
    GerÃ§ek projede X-Forwarded-For baÅŸlÄ±ÄŸÄ±nÄ± da okumak isteyebilirsin.
    Åžimdilik doÄŸrudan client.host kullanÄ±yoruz.
    """
    return request.client.host or "unknown"


def _get_daily_counters(ip: str) -> dict:
    """
    Her IP iÃ§in gÃ¼nlÃ¼k sayaÃ§ tutar.
    GÃ¼n deÄŸiÅŸince sayaÃ§ otomatik sÄ±fÄ±rlanÄ±r.
    """
    today = date.today()
    stats = ip_stats.get(ip)
    if not stats or stats.get("date") != today:
        stats = {"total": 0, "websearch": 0, "date": today}
        ip_stats[ip] = stats
    return stats


# ============================================================
# ====================== ROUTER ==============================
# ============================================================

class RouteQuery(BaseModel):
    datasource: Literal["vectorstore", "websearch"] = Field(
        ...,
        description="Choose whether to use vectorstore or web search."
    )

class StageRoute(BaseModel):
    stage: Literal["info", "nurture", "close"] = Field(
        ...,
        description=(
            "Conversation stage based on the user's question. "
            "'info' = only information seeking, "
            "'nurture' = evaluating options / has concerns, "
            "'close' = asking about price, appointment, or concrete action."
        )
    )



# Router LLM
llm_router = ChatOpenAI(model="gpt-4o-mini", temperature=0)
structured_llm_router = llm_router.with_structured_output(RouteQuery)

system_router = """
You are an expert router.

If the user question is about:
- keloids
- keloid treatments
- cryotherapy
- laser therapy
- corticosteroid injections
- recurrence rates
- medical literature
- wound healing
- clinical guidelines

ALWAYS choose: vectorstore.

For all unrelated questions choose: websearch.
"""

route_prompt = ChatPromptTemplate.from_messages([
    ("system", system_router),
    ("human", "{question}")
])

question_router = route_prompt | structured_llm_router

def fast_route(question: str) -> Literal["vectorstore", "websearch"]:
    """
    Basit keyword kontrolÃ¼yle sorunun keloid ile ilgili olup olmadÄ±ÄŸÄ±nÄ± tahmin eder.
    Bariz keloid / skar sorularÄ±nda direkt vectorstore dÃ¶ner, diÄŸerlerinde websearch.
    """
    q = (question or "").lower()

    keloid_keywords = [
        "keloid",
        "keloit",
        "keloidcare",
        "skar",
        "scar",
        "yara izi",
        "yara izi tedavisi",
        "keloid tedavisi",
        "hypertrophic",
        "hipertrofik",
    ]

    if any(kw in q for kw in keloid_keywords):
        return "vectorstore"
    return "websearch"


# ============================================================
# ============== CONVERSATION STAGE ROUTER ===================
# ============================================================

stage_system_router = """
You are a triage assistant that classifies the user's question
into one of three conversation stages for a medical clinic chatbot.

Stages:
- "info": The user is only seeking general information about keloids,
  causes, treatments, risks, healing, etc. No mention of price, cost,
  appointment, booking, or specific offers.
- "nurture": The user is comparing options, expressing fears or hopes,
  asking about side effects, recurrence, success rates, or suitability.
  They are not yet explicitly asking for prices or appointments,
  but they seem to be evaluating whether this clinic / treatment is right for them.
- "close": The user is asking about price, cost, campaign, discount,
  package details, location, exact dates, appointment, booking, or similar
  decision-oriented topics.

Rules:
- If the question explicitly mentions price, cost, fee, campaign,
  discount, installment, appointment, booking, available dates, or schedule,
  choose "close".
- Else if the question expresses fear, concerns, comparison, or is
  clearly evaluating whether to do treatment (e.g. "should I do it",
  "is it worth it", "is it better than X", "what happens if I don't"),
  choose "nurture".
- Else if it is mostly general medical information about keloids,
  definitions, causes, or treatments, choose "info".
- If in doubt between "info" and "nurture", prefer "nurture".
"""

stage_route_prompt = ChatPromptTemplate.from_messages([
    ("system", stage_system_router),
    ("human", "{question}")
])

# Stage router LLM (aynÄ± modeli kullanabiliriz)
stage_structured_llm = llm_router.with_structured_output(StageRoute)
conversation_stage_router = stage_route_prompt | stage_structured_llm


def detect_stage(user_question: str) -> str:
    """KullanÄ±cÄ±nÄ±n sorusuna gÃ¶re info / nurture / close aÅŸamasÄ±nÄ± belirler."""
    route = conversation_stage_router.invoke({"question": user_question})
    print("STAGE DECISION:", route.stage)
    return route.stage

def build_limit_message(lang_code: str, limit_type: str) -> str:
    """
    limit_type: "total" veya "websearch"
    """
    if lang_code == "tr":
        if limit_type == "total":
            return (
                "GÃ¼venlik nedeniyle, bugÃ¼n bu asistandan en fazla 15 yanÄ±t alabiliyoruz. "
                "BugÃ¼nkÃ¼ sÄ±nÄ±r doldu. Yeni sorularÄ±n iÃ§in lÃ¼tfen yarÄ±n tekrar yazabilir "
                "veya doÄŸrudan kliniÄŸimizle telefon ya da WhatsApp Ã¼zerinden iletiÅŸime geÃ§ebilirsin."
            )
        else:  # websearch
            return (
                "Klinik dÄ±ÅŸÄ±, keloid ile ilgisi olmayan sorularda gÃ¼venlik nedeniyle gÃ¼nde en fazla "
                "3 yanÄ±t verebiliyoruz. Bu sÄ±nÄ±rÄ± doldurdun. "
                "Keloid ve tedavileriyle ilgili sorularÄ±nÄ± ise dilediÄŸin kadar sorabilirsin."
            )
    else:
        if limit_type == "total":
            return (
                "For security reasons you can receive up to 15 answers from this assistant per day. "
                "Youâ€™ve reached todayâ€™s limit. For new questions, please try again tomorrow or contact "
                "our clinic directly by phone or WhatsApp."
            )
        else:
            return (
                "For non-keloid, general questions we can only provide up to 3 answers per day. "
                "Youâ€™ve reached this limit. You can still ask us as many questions as you like "
                "about keloid and scar treatments."
            )

# ============================================================
# ================== GRADE DOCUMENTS (RELEVANCE) =============
# ============================================================

class GradeDocuments(BaseModel):
    """Binary relevance score for a single document."""
    binary_score: str = Field(
        description="Reply 'yes' if the document is relevant to the question, otherwise 'no'."
    )

# LLM for grading
llm_grader = ChatOpenAI(model="gpt-4o-mini", temperature=0)
structured_llm_grader = llm_grader.with_structured_output(GradeDocuments)

grade_docs_system = """
You are a grader checking if a single document is relevant to a user question.

If the document helps answer the question, reply 'yes'.
If it is irrelevant or only weakly related, reply 'no'.

Answer strictly with 'yes' or 'no'.
"""

grade_docs_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", grade_docs_system),
        (
            "human",
            "Question:\n{question}\n\nDocument:\n{document}\n\nIs this document relevant? (yes or no)"
        ),
    ]
)

grade_documents_chain: RunnableSequence = grade_docs_prompt | structured_llm_grader


def filter_relevant_chunks(question: str, chunks: list[str]) -> list[str]:
    """LLM ile her chunk iÃ§in 'relevant mÄ±?' filtresi uygular."""
    relevant = []

    for idx, ch in enumerate(chunks, start=1):
        try:
            result = grade_documents_chain.invoke(
                {"question": question, "document": ch}
            )
            decision = (result.binary_score or "").strip().lower()
            print(f"[GRADE_DOCS] Chunk {idx}: {decision}")

            if decision.startswith("y"):  # yes
                relevant.append(ch)
        except Exception as e:
            print(f"[GRADE_DOCS] Error grading chunk {idx}: {e}")
            # Hata olursa chunk'Ä± atlayabiliriz

    print(f"[GRADE_DOCS] Kept {len(relevant)} / {len(chunks)} chunks")
    return relevant


# ============================================================
# ================== HALLUCINATION CHECKER ===================
# ============================================================

def check_hallucination(documents: str, answer: str) -> bool:
    """CevabÄ±n verilen dokÃ¼manlarla uyumlu olup olmadÄ±ÄŸÄ±nÄ± kontrol eder."""

    prompt = f"""
You are a hallucination checker.
Your task is to determine whether the assistant's answer is fully grounded in the provided context.

If the answer is supported â†’ reply only: YES
If the answer is not supported â†’ reply only: NO

CONTEXT:
{documents}

ANSWER:
{answer}
    """

    resp = client.responses.create(
        model="gpt-4o-mini",
        input=prompt,
        max_output_tokens=32,  # <<< BURAYI DEÄžÄ°ÅžTÄ°RDÄ°K
    )

    result = resp.output_text.strip().upper()
    return result == "YES"

# ============================================================
# ================== LANGUAGE DETECTION ======================
# ============================================================

LANG_NAME_MAP = {
    "tr": "Turkish",
    "en": "English",
    "es": "Spanish",
    "fr": "French",
    "de": "German",
    "el": "Greek",
    "bg": "Bulgarian",
}


def detect_language(text: str) -> tuple[str, str]:
    """
    KullanÄ±cÄ±nÄ±n soru dilini tespit eder.
    ISO 639-1 kodu (tr, en, es...) ve Ä°ngilizce adÄ±nÄ± dÃ¶ner.
    """
    prompt = f"""
Detect the primary language of the following user text.
Respond ONLY with the two-letter ISO 639-1 language code
(e.g. "tr", "en", "es", "fr", "de") and nothing else.

Text:
{text}
"""

    resp = client.responses.create(
        model="gpt-4o-mini",
        input=prompt,
        max_output_tokens=16,   # <<< BURAYI 16 YAP
    )

    code = resp.output_text.strip().lower()
    if code not in LANG_NAME_MAP:
        code = "tr"  # default
    lang_name = LANG_NAME_MAP[code]
    return code, lang_name

WELCOME_MESSAGES = {
    "en": (
        "Hi There! Welcome to The Keloidcare clinic.\n"
        "What should I call you?"
    ),
    "tr": (
        "Merhaba! Keloidcare KliniÄŸine hoÅŸ geldin.\n"
        "Sana nasÄ±l hitap edelim?"
    ),
    "fr": (
        "Salut ! Bienvenue Ã  la clinique Keloidcare.\n"
        "Comment veux-tu quâ€™on tâ€™appelle ?"
    ),
    "de": (
        "Hi! Willkommen in der Keloidcare Klinik.\n"
        "Wie dÃ¼rfen wir dich nennen?"
    ),
    "el": (
        "Î“ÎµÎ¹Î± ÏƒÎ¿Ï…! ÎšÎ±Î»ÏŽÏ‚ Î®ÏÎ¸ÎµÏ‚ ÏƒÏ„Î·Î½ ÎºÎ»Î¹Î½Î¹ÎºÎ® Keloidcare.\n"
        "Î ÏŽÏ‚ Î½Î± ÏƒÎµ Ï†Ï‰Î½Î¬Î¶Î¿Ï…Î¼Îµ;"
    ),
    "bg": (
        "Ð—Ð´Ñ€Ð°ÑÑ‚Ð¸! Ð”Ð¾Ð±Ñ€Ðµ Ð´Ð¾ÑˆÑŠÐ»/Ð´Ð¾ÑˆÐ»Ð° Ð² ÐºÐ»Ð¸Ð½Ð¸ÐºÐ°Ñ‚Ð° Keloidcare.\n"
        "ÐšÐ°Ðº Ð´Ð° Ñ‚Ðµ Ð½Ð°Ñ€Ð¸Ñ‡Ð°Ð¼Ðµ?"
    ),
    "es": (
        "Â¡Hola! Bienvenido a la clÃ­nica Keloidcare.\n"
        "Â¿CÃ³mo quieres que te llamemos?"
    ),
}

# IP'den Ã¼lke kodu geldiÄŸinde hangi dili kullanacaÄŸÄ±mÄ±z
COUNTRY_LANG_MAP = {
    "FR": "fr",
    "DE": "de",
    "GR": "el",   # Yunanistan
    "BG": "bg",
    "TR": "tr",
}

def get_country_code_from_ip(ip: str) -> str | None:
    """
    IP'den Ã¼lke kodu almak iÃ§in basit bir servis kullanÄ±yoruz.
    Prod ortamÄ±nda istersen farklÄ± bir provider'a geÃ§ebilirsin.
    """
    try:
        if not ip or ip in ("127.0.0.1", "::1", "localhost"):
            return None

        resp = requests.get(f"https://ipapi.co/{ip}/json/", timeout=2)
        if resp.status_code == 200:
            data = resp.json()
            code = data.get("country_code")
            if isinstance(code, str):
                return code.upper()
    except Exception as e:
        print("IP geolocation error:", e)
    return None


def get_preferred_lang_from_request(request: Request) -> str:
    """
    1) Ã–nce IP'den Ã¼lke kodunu bul.
       - FR -> FransÄ±zca
       - DE -> Almanca
       - GR -> Yunanca
       - BG -> Bulgarca
       - TR -> TÃ¼rkÃ§e
       - DiÄŸer tÃ¼m Ã¼lkeler -> Ä°ngilizce
    2) IP'den Ã¼lke alÄ±namazsa (localhost vs.)
       Accept-Language'e gÃ¶re tahmin et, yine yoksa Ä°ngilizce.
    """
    ip = _get_ip(request)
    country_code = get_country_code_from_ip(ip)

    if country_code:
        if country_code in COUNTRY_LANG_MAP:
            return COUNTRY_LANG_MAP[country_code]
        # tanÄ±dÄ±ÄŸÄ±mÄ±z ama map'te olmayan Ã¼lke -> Ä°ngilizce
        return "en"

    # fallback: Accept-Language
    header = request.headers.get("accept-language", "")
    if header:
        first = header.split(",")[0].strip()
        if "-" in first:
            first = first.split("-")[0]
        code = first.lower()
        if code in LANG_NAME_MAP:
            return code

    return "en"



def get_welcome_message(lang_code: str) -> str:
    return WELCOME_MESSAGES.get(lang_code, WELCOME_MESSAGES["en"])


def build_intro_messages(lang_code: str, name: str) -> list[str]:
    """
    Ä°lk karÅŸÄ±lama sonrasÄ± isim ve e-posta sorularÄ±.
    Dil bulunamazsa Ä°ngilizce dÃ¶ner.
    """
    templates = {
        "en": (
            "I am Nicole! Nice to meet you, {name}!",
            "May I know your email {name}? so I can get back to you if needed."
        ),
        "tr": (
            "Ben Nicole! TanÄ±ÅŸtÄ±ÄŸÄ±mÄ±za memnun oldum, {name}!",
            "{name}, e-posta adresini alabilir miyim? Gerekirse sana dÃ¶nebilmem iÃ§in."
        ),
        "fr": (
            "Je suis Nicole ! Ravi de te rencontrer, {name} !",
            "Puis-je avoir ton email {name} ? Ainsi je pourrai te recontacter si besoin."
        ),
        "de": (
            "Ich bin Nicole! SchÃ¶n, dich kennenzulernen, {name}!",
            "Darf ich deine E-Mail {name} haben, damit ich mich bei Bedarf melden kann?"
        ),
        "el": (
            "Î•Î¯Î¼Î±Î¹ Î· Nicole! Î§Î±Î¯ÏÎ¿Î¼Î±Î¹ Ï€Î¿Ï… ÏƒÎµ Î³Î½Ï‰ÏÎ¯Î¶Ï‰, {name}!",
            "ÎœÏ€Î¿ÏÏŽ Î½Î± Î­Ï‡Ï‰ Ï„Î¿ email ÏƒÎ¿Ï… {name}; ÏŽÏƒÏ„Îµ Î½Î± Î¼Ï€Î¿ÏÏŽ Î½Î± ÏƒÎµ ÎµÎ½Î·Î¼ÎµÏÏŽÏƒÏ‰ Î±Î½ Ï‡ÏÎµÎ¹Î±ÏƒÏ„ÎµÎ¯."
        ),
        "bg": (
            "ÐÐ· ÑÑŠÐ¼ ÐÐ¸ÐºÐ¾Ð»! ÐŸÑ€Ð¸ÑÑ‚Ð½Ð¾ Ð¼Ð¸ Ðµ Ð´Ð° ÑÐµ Ð·Ð°Ð¿Ð¾Ð·Ð½Ð°ÐµÐ¼, {name}!",
            "ÐœÐ¾Ð³Ð° Ð»Ð¸ Ð´Ð° Ð²Ð·ÐµÐ¼Ð° Ð¸Ð¼ÐµÐ¹Ð»Ð° Ñ‚Ð¸, {name}, Ð·Ð° Ð´Ð° ÑÐµ ÑÐ²ÑŠÑ€Ð¶Ð° Ð¿Ñ€Ð¸ Ð½ÑƒÐ¶Ð´Ð°?"
        ),
    }

    msg1, msg2 = templates.get(lang_code, templates["en"])
    return [msg1.format(name=name), msg2.format(name=name)]


def build_invalid_email_message(lang_code: str, name: str) -> str:
    """
    HatalÄ± e-posta mesajÄ±nÄ± diline gÃ¶re dÃ¶ner, bulunamazsa Ä°ngilizce.
    """
    templates = {
        "en": (
            "No problem {name}, if you do not want to share your email address! "
            "I am here to find what you need. What are you looking for?"
        ),
        "tr": (
            "HiÃ§ sorun deÄŸil {name}, e-posta adresini paylaÅŸmak istemezsen! "
            "Ä°htiyacÄ±n olanÄ± bulmana yardÄ±m etmek iÃ§in buradayÄ±m. Ne arÄ±yorsun?"
        ),
        "fr": (
            "Pas de souci {name} si tu ne veux pas partager ton email ! "
            "Je suis lÃ  pour tâ€™aider. Que recherches-tu ?"
        ),
        "de": (
            "Kein Problem {name}, falls du deine E-Mail nicht teilen mÃ¶chtest! "
            "Ich bin hier, um zu finden, was du brauchst. Wonach suchst du?"
        ),
        "el": (
            "ÎšÎ±Î½Î­Î½Î± Ï€ÏÏŒÎ²Î»Î·Î¼Î± {name} Î±Î½ Î´ÎµÎ½ Î¸Î­Î»ÎµÎ¹Ï‚ Î½Î± Î¼Î¿Î¹ÏÎ±ÏƒÏ„ÎµÎ¯Ï‚ Ï„Î¿ email ÏƒÎ¿Ï…! "
            "Î•Î¯Î¼Î±Î¹ ÎµÎ´ÏŽ Î³Î¹Î± Î½Î± Î²ÏÏ‰ Î±Ï…Ï„ÏŒ Ï€Î¿Ï… Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏƒÎ±Î¹. Î¤Î¹ ÏˆÎ¬Ï‡Î½ÎµÎ¹Ï‚;"
        ),
        "bg": (
            "ÐÑÐ¼Ð° Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼ {name}, Ð°ÐºÐ¾ Ð½Ðµ Ð¸ÑÐºÐ°Ñˆ Ð´Ð° ÑÐ¿Ð¾Ð´ÐµÐ»Ð¸Ñˆ Ð¸Ð¼ÐµÐ¹Ð»Ð° ÑÐ¸! "
            "Ð¢ÑƒÐº ÑÑŠÐ¼, Ð·Ð° Ð´Ð° Ð½Ð°Ð¼ÐµÑ€Ñ Ð¾Ñ‚ ÐºÐ°ÐºÐ²Ð¾ Ð¸Ð¼Ð°Ñˆ Ð½ÑƒÐ¶Ð´Ð°. ÐšÐ°ÐºÐ²Ð¾ Ñ‚ÑŠÑ€ÑÐ¸Ñˆ?"
        ),
    }
    return templates.get(lang_code, templates["en"]).format(name=name)


def build_email_thanks_message(lang_code: str, name: str) -> str:
    """
    GeÃ§erli e-posta sonrasÄ± teÅŸekkÃ¼r mesajÄ±, bulunamazsa Ä°ngilizce.
    """
    templates = {
        "en": (
            "Thank you {name}! I am here to find what you need. What are you looking for?"
        ),
        "tr": (
            "TeÅŸekkÃ¼rler {name}! Ä°htiyacÄ±n olanÄ± bulmana yardÄ±m etmek iÃ§in buradayÄ±m. Ne arÄ±yorsun?"
        ),
        "fr": (
            "Merci {name} ! Je suis lÃ  pour tâ€™aider Ã  trouver ce dont tu as besoin. Que recherches-tu ?"
        ),
        "de": (
            "Danke {name}! Ich bin hier, um zu finden, was du brauchst. Wonach suchst du?"
        ),
        "el": (
            "Î•Ï…Ï‡Î±ÏÎ¹ÏƒÏ„Î¿ÏÎ¼Îµ {name}! Î•Î¯Î¼Î±Î¹ ÎµÎ´ÏŽ Î³Î¹Î± Î½Î± Î²ÏÏ‰ Î±Ï…Ï„ÏŒ Ï€Î¿Ï… Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏƒÎ±Î¹. Î¤Î¹ ÏˆÎ¬Ï‡Î½ÎµÎ¹Ï‚;"
        ),
        "bg": (
            "Ð‘Ð»Ð°Ð³Ð¾Ð´Ð°Ñ€Ñ Ñ‚Ð¸, {name}! Ð¢ÑƒÐº ÑÑŠÐ¼, Ð·Ð° Ð´Ð° Ð½Ð°Ð¼ÐµÑ€Ð¸Ð¼ Ð¾Ñ‚ ÐºÐ°ÐºÐ²Ð¾ Ð¸Ð¼Ð°Ñˆ Ð½ÑƒÐ¶Ð´Ð°. ÐšÐ°ÐºÐ²Ð¾ Ñ‚ÑŠÑ€ÑÐ¸Ñˆ?"
        ),
    }
    return templates.get(lang_code, templates["en"]).format(name=name)



# ================== LEAD MODELLERÄ° ve AIRTABLE ENTEGRASYONU ==================

class ChatMessage(BaseModel):
    role: str    # "user" veya "assistant"
    content: str

class NameRequest(BaseModel):
    name: str


class EmailRequest(BaseModel):
    name: str
    email: str

class LeadPayload(BaseModel):
    name: str | None = None
    phone: str | None = None
    email: str | None = None
    message: str | None = None               # Son mesaj / not (opsiyonel)
    conversation: list[ChatMessage] | None = None  # TÃ¼m sohbet (opsiyonel)


def summarize_conversation(conversation: list[ChatMessage]) -> str | None:
    """Sohbeti doktor iÃ§in 5â€“7 madde halinde Ã¶zetler."""
    if not conversation:
        return None

    text = "\n".join([f"{m.role}: {m.content}" for m in conversation])

    resp = client.responses.create(
        model="gpt-4o-mini",
        input=f"""
You are a medical assistant at a keloid clinic.

Summarize the following conversation between a patient and the KeloidCare Clinic AI
in 5â€“7 concise bullet points in English.

Focus on:
- main keloid complaints (location, duration, symptoms)
- previous treatments and responses
- patient concerns and expectations
- any mentioned comorbidities or medications

CONVERSATION:
{text}
""",
        max_output_tokens=250,
    )
    return resp.output_text.strip()

def send_lead_to_airtable(payload: LeadPayload):
    """Hasta iletiÅŸim bilgilerini + sohbet Ã¶zetini Airtable'a kaydeder."""

    summary = summarize_conversation(payload.conversation) if payload.conversation else None

    fields: dict[str, str] = {}

    if payload.name:
        fields["Name"] = payload.name
    if payload.phone:
        fields["Phone"] = payload.phone
    if payload.email:
        fields["Email"] = payload.email
    if payload.message:
        fields["PatientMessage"] = payload.message
    if summary:
        fields["ConversationSummary"] = summary

    if not fields:
        raise RuntimeError("No lead fields to send to Airtable")

    url = f"https://api.airtable.com/v0/{AIRTABLE_BASE_ID}/{AIRTABLE_TABLE_NAME}"
    headers = {
        "Authorization": f"Bearer {AIRTABLE_API_KEY}",
        "Content-Type": "application/json",
    }
    data = {
        "records": [
            {"fields": fields}
        ]
    }

    r = requests.post(url, headers=headers, json=data)

    # DEBUG
    print("\n--- AIRTABLE DEBUG LOG ---")
    print("URL:", url)
    print("Headers:", headers)
    print("Payload:", data)
    print("Response Code:", r.status_code)
    print("Response Body:", r.text)
    print("--- END DEBUG LOG ---\n")

    if r.status_code not in (200, 201, 202):
        raise RuntimeError(f"Airtable error: {r.status_code} {r.text}")

    return r.json()





# ============================================================
# ====================== RAG System ==========================
# ============================================================

def rag_answer(query: str, lang_info: tuple[str, str] | None = None) -> tuple[str, str]:
    """
    RAG pipeline â€” translate â†’ retrieve â†’ GRADE_DOCUMENTS â†’ answer.
    Returns (answer, source), where source âˆˆ {"rag", "websearch", "empty"}.

    LLM, keloid kliniÄŸi adÄ±na konuÅŸur ve cevabÄ± her zaman
    kullanÄ±cÄ±nÄ±n soru dilinde verir.
    """

    # 0) KullanÄ±cÄ±nÄ±n dilini tespit et (hazÄ±r varsa kullan)
    if lang_info is None:
        lang_code, lang_name = detect_language(query)
        lang_info = (lang_code, lang_name)
    else:
        lang_code, lang_name = lang_info

    # 1) Soru Ä°ngilizceye Ã§evrilir (sadece arama iÃ§in kullanÄ±yoruz)
    translation_resp = client.responses.create(
        model="gpt-4o-mini",
        input=f"Translate this query to English (only English output): {query}",
        max_output_tokens=64,
    )
    translated_query = translation_resp.output_text.strip()

    # 2) Vector store'dan chunk'lar Ã§ekilir
    search = client.responses.create(
        model="gpt-4o-mini",
        input=translated_query,
        tools=[{
            "type": "file_search",
            "vector_store_ids": [VECTOR_STORE_ID],
            # grade_documents kullanÄ±lacaÄŸÄ± iÃ§in 6â€“8 gibi biraz yÃ¼ksek tutmak mantÄ±klÄ±
            "max_num_results": 4
        }],
        include=["file_search_call.results"]
    )

    chunks: list[str] = []
    for item in search.output:
        if item.type == "file_search_call":
            for r in item.results:
                chunks.append(r.text)

    print(f"\nRetrieved chunks (raw): {len(chunks)}")

    # 2.5) HiÃ§ chunk yoksa â†’ internal dokÃ¼manlardan cevap yok
    if len(chunks) == 0:
        no_answer_prompt = f"""
You are a medical assistant working for a specialized keloid clinic.

The user asked (in {lang_name}):
{query}

There is no relevant information about this in the clinic's internal documents.
You must answer in {lang_name} only.

Politely explain that our clinic does not have enough document-based data
for this specific question and that the user should consult our doctors
directly for a personalized evaluation.

Speak as "we" / "our clinic", not as an AI model.
"""
        resp = client.responses.create(
            model="gpt-4o-mini",
            input=no_answer_prompt,
            max_output_tokens=200,
        )
        return resp.output_text.strip(), "empty"

    # 3) GRADE_DOCUMENTS â†’ sadece ilgili chunk'lar kalsÄ±n
    # Burada istersen translated_query yerine query de kullanabilirsin.
    graded_chunks = filter_relevant_chunks(translated_query, chunks)

    print(f"[GRADE_DOCS] After grading: {len(graded_chunks)} relevant chunks")

    # EÄŸer grading sonrasÄ± hiÃ§ chunk kalmadÄ±ysa, dokÃ¼manlardan cevap veremiyoruz
    if len(graded_chunks) == 0:
        no_answer_prompt = f"""
You are a medical assistant working for a specialized keloid clinic.

The user asked (in {lang_name}):
{query}

We found documents, but none of them are clearly relevant to this question.
You must answer in {lang_name} only.

Politely explain that our clinic does not have enough document-based data
for this specific question and that the user should consult our doctors
directly for a personalized evaluation.

Speak as "we" / "our clinic", not as an AI model.
"""
        resp = client.responses.create(
            model="gpt-4o-mini",
            input=no_answer_prompt,
            max_output_tokens=200,
        )
        return resp.output_text.strip(), "empty"

    # 4) Context artÄ±k SADECE ilgili chunk'lardan oluÅŸuyor
    context = "\n\n".join(graded_chunks)

    # 5) Bu context'e dayanarak (kullanÄ±cÄ± dili ile) cevap Ã¼ret
    final = client.responses.create(
        model="gpt-4o",
        input=f"""
You are a medical assistant for a specialized keloid clinic.

The user's language is: {lang_name} (code: {lang_code}).
User question (keep its original wording and answer in this language):
{query}

You speak on behalf of the clinic using "we" / "our clinic", not as an abstract AI.

Use ONLY the context below to answer the user's question.
If the context does not contain the answer, say that we don't know from
our documents and recommend consulting our doctors directly.

You MUST answer ONLY in {lang_name}, even if the context is in a different language.
Translate any necessary information from the context into {lang_name}.

CONTEXT:
{context}
""",
        max_output_tokens=350
    )

    answer = final.output_text

    # 6) HALLUCINATION CHECK (artÄ±k graded context'e gÃ¶re)
    is_grounded = check_hallucination(context, answer)

    if not is_grounded:
        print("âš ï¸ HALLUCINATION DETECTED â†’ FALLBACK WEBSEARCH")
        ws_answer = websearch_answer(query, lang_info=lang_info)
        return ws_answer, "websearch"

    # 7) Her ÅŸey yolundaysa â†’ cevabÄ± dÃ¶ndÃ¼r
    # (CTA akÄ±ÅŸÄ± satÄ±ÅŸ katmanÄ±nda eklenecek)
    return answer, "rag"




# ============================================================
# =============== SALES STYLE POST-PROCESSOR =================
# ============================================================

SALES_PLAYBOOK = {
    "info": {
        "tone": (
            "Calm, educational, empowering. Recognize that learning about keloids early is wise."
        ),
        "intro": (
            "Open with gratitude for reaching out and reinforce that sharing knowledge freely is part of our care."
        ),
        "closing": (
            "Invite them to request complimentary resources (PDF, baÅŸarÄ± hikayeleri, kÄ±sa video) "
            "and remind that final decisions follow a doctor evaluation."
        ),
        "tactics": [
            "Reciprocity: mention that we happily share analyses, baÅŸarÄ± hikayeleri or guidance without obligation.",
            "Authority: highlight that our medical team and technology (lazer, soÄŸutma, bakÄ±m protokolleri) are curated for keloids without adding new clinical claims.",
            "Consistency: assure that the same information is reflected across WhatsApp, PDF'ler ve klinik gÃ¶rÃ¼ÅŸmeleri.",
        ],
        "cues": [
            "Offer fast follow-up options (Ã¶r. WhatsApp, sesli mesaj) even if they cannot respond immediately.",
            "Encourage them to keep asking questions and remind that sabÄ±r + dÃ¼zen takibi kritik.",
        ],
    },
    "nurture": {
        "tone": (
            "Warm, story-driven, empathetic. Normalize their kararsÄ±zlÄ±k and create emotional closeness."
        ),
        "intro": (
            "Reference that many visitors feel the same and we listen closely before Ã¶neri yapmak."
        ),
        "closing": (
            "Invite them to share birkaÃ§ detay so we can craft a kiÅŸiye Ã¶zel plan and schedule a free evaluation call if they wish."
        ),
        "tactics": [
            "Liking: use their name if available, mirror their vibe, show gerÃ§ek bir insan ilgisi.",
            "Yes Ladder: build kÃ¼Ã§Ã¼k onaylar (sÃ¼reÃ§ uzun, kaÅŸÄ±ntÄ± olabilir, Ã§Ã¶zÃ¼m gÃ¶rmek ister misiniz?) before proposing evaluation.",
            "Storytelling & Social Proof: refer to anonymized baÅŸarÄ± hikayeleri or how birÃ§ok hastaya eÅŸlik ettiÄŸimizi belirt (no numbers).",
            "Repetition & Patience: reassure that it's normal to revisit sorular and we gladly explain again.",
        ],
        "cues": [
            "Mention that we can send kÄ±sa video / ses notu if they prefer to feel the team's presence.",
            "Hint that we log their notes so nothing kaybolur and we follow up nazikÃ§e (Ã¶r. 3 gÃ¼n / 7 gÃ¼n ritmi).",
        ],
    },
    "close": {
        "tone": (
            "Confident, action-oriented but gentle. Reduce friction around booking or fiyat konuÅŸmasÄ±nÄ±n yÃ¶ntemi."
        ),
        "intro": (
            "Affirm that taking action now prevents keloidlarÄ±n sertleÅŸip yayÄ±lmasÄ±nÄ± and that we already reserve time for them."
        ),
        "closing": (
            "Use assumption language (hangi gÃ¼n uygun olur) + scarcity/deadline cues (kontenjan dolmadan) "
            "and remind that full plan & Ã¼cret only netleÅŸir after evaluation. Offer Ã¼cretsiz analiz or memnuniyet garantili ilk gÃ¶rÃ¼ÅŸme opsiyonu."
        ),
        "tactics": [
            "Fear/Responsibility: gently outline that gecikmek daha agresif tedavilere neden olabilir, so erken planlama deÄŸerlidir.",
            "Freebie: highlight Ã¼cretsiz cilt analizi veya ilk gÃ¶rÃ¼ÅŸmede memnuniyet garantisi.",
            "Assumption Technique: speak as if they already chose us and only scheduling details remain.",
            "Deadline & Scarcity: mention limited kampanya sÃ¼releri veya doktor kontenjanlarÄ±nÄ±n hÄ±zla dolduÄŸu (no exact numbers/dates).",
        ],
        "cues": [
            "Offer to lock a provisional slot and promise nazik hatÄ±rlatmalar (WhatsApp ping, kÄ±sa arama).",
            "Reassure that we document seÃ§imlerini in CRM so fiyat / kampanya tutarlÄ±lÄ±ÄŸÄ± bozulmaz.",
        ],
    },
}

COMMON_SALES_GUARDRAILS = """
- Keep intro + closing together under roughly four sentences; be concise.
- Mirror the user's language style and emoji usage (if they add ðŸ˜Š you may add one benzer emoji).
- Never invent medical details, prices, rakamlar or guarantees; reference doctor evaluation for personalization.
- Highlight that we are reachable via WhatsApp, sesli mesaj or video if they prefer warmer iletiÅŸim.
- Mention that we log follow-up notes (CRM) so nobody feels forgotten and bilgilerin tutarlÄ±lÄ±ÄŸÄ± korunur.
"""


def _build_stage_instruction(stage: str) -> str:
    data = SALES_PLAYBOOK.get(stage, SALES_PLAYBOOK["info"])
    tactics_block = "\n".join(f"- {item}" for item in data.get("tactics", []))
    cues_block = "\n".join(f"- {item}" for item in data.get("cues", []))
    return f"""
Tone focus: {data['tone']}
Intro focus: {data['intro']}
Closing/CTA focus: {data['closing']}

Preferred persuasion cues (weave in naturally, maks 1 cÃ¼mle):
{tactics_block}

Conversation micro-cues:
{cues_block}
"""

def build_flow4_cta(lang_code: str) -> str:
    """
    KullanÄ±cÄ±nÄ±n durumuna Ã¶zel randevu / tedavi seÃ§enekleri iÃ§in
    iletiÅŸim izni isteyen CTA.
    """
    if lang_code == "tr":
        return (
            "Ä°stersen senin durumuna Ã¶zel randevu ve tedavi seÃ§eneklerini de paylaÅŸabiliriz. "
            "Bunun iÃ§in bir-iki iletiÅŸim bilgine ihtiyacÄ±mÄ±z olacak. Uygun mu?"
        )
    elif lang_code == "fr":
        return (
            "Si tu veux, nous pouvons aussi te proposer des options de rendez-vous et de traitement adaptÃ©es Ã  ta situation. "
            "Pour cela, nous aurons besoin de quelques informations de contact. Est-ce que Ã§a te convient ?"
        )
    else:
        return (
            "If you like, we can also share appointment and treatment options tailored to your situation. "
            "For that weâ€™ll need one or two contact details from you. Is that okay?"
        )

def apply_sales_style(
    user_question: str,
    base_answer: str,
    stage: str,
    lang_info: tuple[str, str] | None = None,
    user_name: str | None = None,
) -> str:

    """
    TÄ±bbi olarak doÄŸrulanmÄ±ÅŸ cevabÄ± (base_answer) HÄ°Ã‡ DEÄžÄ°ÅžTÄ°RMEZ.
    Sadece, aÅŸamaya (info / nurture / close) gÃ¶re:
    - kÄ±sa bir giriÅŸ (intro)
    - kÄ±sa bir kapanÄ±ÅŸ (closing / CTA) ekler.

    'close' aÅŸamasÄ±nda, kapanÄ±ÅŸÄ±n sonuna Flow 4'te tarif ettiÄŸin
    Ã¶zel CTA cÃ¼mlesini ekliyoruz.
    """
    if lang_info is None:
        lang_code, lang_name = detect_language(user_question)
        lang_info = (lang_code, lang_name)
    else:
        lang_code, lang_name = lang_info

    stage_instructions = _build_stage_instruction(stage)

    safe_name = (user_name or "").strip()
    if safe_name:
        name_instruction = (
            f'The user\'s name is "{safe_name}". '
            f'Use this name at most once, either in the intro or in the closing, '
            f'in a natural way of addressing them. Do NOT repeat the name in every sentence.'
        )
    else:
        name_instruction = "You do not know the user's name. Do not invent one."

    prompt = f"""
You are a patient advisor and sales-oriented representative for a specialized keloid clinic.

The user's language is: {lang_name} (code: {lang_code}).
You MUST write both paragraphs ONLY in {lang_name}.
If the user's question is in Turkish, write in Turkish.
If it is in English, write in English.

{name_instruction}

You will NOT write the medical explanation. That part is already prepared.
Your job is ONLY to write:
- a SHORT intro paragraph
- and a SHORT closing / CTA paragraph.

You MUST:
- Speak on behalf of the clinic as "we" / "our clinic", not as an AI model.
- NOT describe specific medical procedures, drugs, doses, or success rates.
- Refer to the medical explanation only in general terms, like
  "aÅŸaÄŸÄ±daki bilgiler", "aÅŸaÄŸÄ±da paylaÅŸÄ±lan tedavi seÃ§enekleri" etc.
- NOT add any numerical claims (%, number of patients, years, etc.).
- NOT give any guarantee of results.

Conversation stage: {stage}

Stage-specific guidelines:
{stage_instructions}

Universal guardrails:
{COMMON_SALES_GUARDRAILS}

OUTPUT FORMAT (important):
[INTRO]
<your intro paragraph in {lang_name}>

[CLOSING]
<your closing / CTA paragraph in {lang_name}>

Do not mention the tags [INTRO] or [CLOSING] to the user; they are just for parsing.
"""


    resp = client.responses.create(
        model="gpt-4o-mini",
        input=prompt,
        max_output_tokens=300,
    )

    raw = resp.output_text.strip()
    intro = ""
    closing = ""

    if "[INTRO]" in raw and "[CLOSING]" in raw:
        try:
            after_intro = raw.split("[INTRO]", 1)[1]
            intro_part, closing_part = after_intro.split("[CLOSING]", 1)
            intro = intro_part.strip()
            closing = closing_part.strip()
        except Exception:
            intro = raw.strip()
            closing = ""
    else:
        intro = raw

    # Flow 4 CTA: sadece "close" aÅŸamasÄ±nda, kapanÄ±ÅŸÄ±n sonuna ekle
    if stage == "close":
        flow_cta = build_flow4_cta(lang_code)
        if closing:
            closing = f"{closing}\n\n{flow_cta}"
        else:
            closing = flow_cta

    parts = []
    if intro:
        parts.append(intro)
    if base_answer:
        parts.append(base_answer)
    if closing:
        parts.append(closing)

    final_answer = "\n\n".join(parts)
    return final_answer


# ============================================================
# ====================== WEBSEARCH ============================
# ============================================================

def websearch_answer(query: str, lang_info: tuple[str, str] | None = None) -> str:
    """
    If RAG fails or router decides, use websearch.
    AMA:
    - BaÅŸka kliniklerin fiyatÄ±nÄ±/verdiÄŸi rakamlarÄ± ASLA sÃ¶yleme.
    - HiÃ§bir ÅŸekilde net fiyat, aralÄ±k, USD/Euro/TL rakamÄ± verme.
    - BaÅŸka klinik / hastane / marka adÄ± verme.
    """
    if lang_info is None:
        lang_code, lang_name = detect_language(query)
        lang_info = (lang_code, lang_name)
    else:
        lang_code, lang_name = lang_info

    prompt = f"""
You are an assistant speaking on behalf of our specialized keloid clinic.

The user's language is: {lang_name} (code: {lang_code}).
You MUST answer ONLY in {lang_name}.

IMPORTANT RESTRICTIONS:
- Do NOT mention any specific prices, cost ranges, currencies, or numeric estimates.
- Do NOT mention or promote other clinics, brand names, hospitals, or websites.
- Even if web search results contain prices or other clinics, you MUST ignore them.
- You can explain which factors affect the cost (lesion size, location, number of sessions, etc.),
  but you must NOT give numbers.
- ALWAYS say that exact pricing in our clinic is determined only after an in-person or online
  evaluation by our doctors.

Use web search ONLY to improve the quality of general medical information (e.g. treatment options),
but NEVER to give concrete costs or name other providers.

User question:
{query}
"""

    resp = client.responses.create(
        model="gpt-4o-mini",
        input=prompt,
        tools=[{"type": "web_search"}],
        max_output_tokens=350,
    )
    return resp.output_text


# ============================================================
# ====================== SMART ANSWER =========================
# ============================================================

def smart_answer(
    user_question: str,
    precomputed_route=None,
    lang_info: tuple[str, str] | None = None,
    user_name: str | None = None,
) -> tuple[str, dict]:

    """
    Cevap + metadata dÃ¶ner.
    meta = {
      "datasource": "vectorstore" | "websearch",
      "source": "rag" | "websearch" | "empty",
      "stage": "info" | "nurture" | "close" | None
    }
    """
    if lang_info is None:
        lang_info = detect_language(user_question)

    # ðŸ”¹ BURASI DEÄžÄ°ÅžTÄ°
    if precomputed_route is None:
        # Ã–nce hÄ±zlÄ± kural tabanlÄ± router ile tahmin et
        fast_ds = fast_route(user_question)

        if fast_ds == "vectorstore":
            # Bariz keloid / skar sorularÄ±nda LLM router'a gerek yok
            route = RouteQuery(datasource="vectorstore")
        else:
            # DiÄŸer sorularda LLM router devreye girsin
            route = question_router.invoke({"question": user_question})
    else:
        # DÄ±ÅŸarÄ±dan hazÄ±r route geldiyse onu kullan
        route = precomputed_route

    datasource = route.datasource
    print("ROUTER DECISION:", datasource)

    meta = {"datasource": datasource, "source": None, "stage": None}

    # 2) EÄŸer keloid / medikal iÃ§erik â†’ vectorstore + RAG
    if datasource == "vectorstore":
        base_answer, source = rag_answer(user_question, lang_info=lang_info)
        meta["source"] = source

        # RAG hiÃ§ cevap bulamadÄ±ysa â†’ direkt websearch
        if source == "empty" or (base_answer is None):
            print("FALLBACK â†’ WEBSEARCH (no RAG answer)")
            answer = websearch_answer(user_question, lang_info=lang_info)
            meta["source"] = "websearch"
            return answer, meta

        # EÄŸer cevap zaten websearch'ten geldiyse (hallucination fallback)
        if source == "websearch":
            stage = detect_stage(user_question)
            meta["stage"] = stage
            styled = apply_sales_style(
                user_question, base_answer, stage, lang_info=lang_info, user_name=user_name
            )
            return styled, meta

        # Kaynak gerÃ§ekten RAG ise â†’ satÄ±ÅŸ stil filtresi uygula
        stage = detect_stage(user_question)
        meta["stage"] = stage
        styled_answer = apply_sales_style(
            user_question, base_answer, stage, lang_info=lang_info, user_name=user_name
        )
        return styled_answer, meta

    # 3) Keloid dÄ±ÅŸÄ± sorularda â†’ direkt websearch (yine soru diliyle, klinik adÄ±na)
    else:
        answer = websearch_answer(user_question, lang_info=lang_info)
        meta["source"] = "websearch"
        return answer, meta

# ============================================================
# =========================== TEST ===========================
# ============================================================

if __name__ == "__main__":
    print("\n--- TEST 1 (Keloid Question â†’ Vectorstore) ---")
    print(smart_answer("Keloidlerim kizardi, cok korkuyorum ne yapmaliyim"))


# ============================================================
# ========================== FASTAPI =========================
# ============================================================

app = FastAPI()

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/welcome")
async def welcome(request: Request):
    """
    Chat aÃ§Ä±ldÄ±ÄŸÄ±nda front-end burayÄ± Ã§aÄŸÄ±rÄ±p
    uygun dilde karÅŸÄ±lama metnini alabilir.
    """
    lang_code = get_preferred_lang_from_request(request)
    return {"lang": lang_code, "message": get_welcome_message(lang_code)}

@app.post("/intro/name")
async def intro_name(payload: NameRequest, request: Request):
    """
    KullanÄ±cÄ± adÄ±nÄ± yazdÄ±ktan sonraki adÄ±m.
    2 mesaj dÃ¶ner (IP / Accept-Language ile tespit edilen dilde):
      1) I am Nicole! Nice to meet you, <name>!
      2) May I know your email <name>? so I can get back to you if needed.
    """
    name = (payload.name or "").strip() or "there"
    lang_code = get_preferred_lang_from_request(request)
    messages = build_intro_messages(lang_code, name)

    return {
        "name": name,
        "messages": messages,
    }


@app.post("/intro/email")
async def intro_email(payload: EmailRequest, request: Request):
    """
    KullanÄ±cÄ± email girdikten sonraki adÄ±m.
    - Email formatÄ± doÄŸruysa -> Airtable'a (name + email) kaydedilir,
      sonra CTA mesajÄ± dÃ¶ner.
    - Email formatÄ± yanlÄ±ÅŸsa -> Airtable'a hiÃ§bir ÅŸey gÃ¶nderilmez,
      ÅŸu mesaj dÃ¶ner:
      "No problem name, if you do not want to share your email address! ..."
    """
    name = (payload.name or "").strip() or "there"
    lang_code = get_preferred_lang_from_request(request)
    email = (payload.email or "").strip()

    # 4. madde: yanlÄ±ÅŸ format veya kullanÄ±cÄ± vermek istemiyor
    if not is_valid_email(email):
        msg = build_invalid_email_message(lang_code, name)
        return {
            "name": name,
            "email": None,
            "valid": False,
            "messages": [msg],
        }

    # 3. madde: email formatÄ± doÄŸru -> Airtable'a yolla
    try:
        lead_payload = LeadPayload(
            name=name,
            email=email,
            message=None,
            conversation=None,
        )
        send_lead_to_airtable(lead_payload)
    except Exception as e:
        # Airtable hatasÄ±nÄ± logla ama kullanÄ±cÄ±ya hata gÃ¶sterme
        print("Error sending lead to Airtable:", e)

    msg = build_email_thanks_message(lang_code, name)

    return {
        "name": name,
        "email": email,
        "valid": True,
        "messages": [msg],
    }


@app.post("/ask")
async def ask_api(payload: dict, request: Request):
    question = (payload.get("question") or "").strip()
    if not question:
        return {"answer": ""}

    # ðŸ‘‡ front-end'ten (widget'tan) gelen isim
    user_name = (payload.get("name") or "").strip() or None

    # IP bazlÄ± sayaÃ§larÄ± al / gÃ¼ncelle
    ip = _get_ip(request)
    stats = _get_daily_counters(ip)

    # Dil tespiti (limit mesajlarÄ± iÃ§in)
    lang_seed = question or "Merhaba"
    lang_code, lang_name = detect_language(lang_seed)
    lang_info = (lang_code, lang_name)

    # ðŸ”¹ Ã–nce hÄ±zlÄ± router ile kaba bir tahmin yap
    fast_ds = fast_route(question)

    # 1) Toplam gÃ¼nlÃ¼k limit kontrolÃ¼ (15 cevap)
    if stats["total"] >= TOTAL_DAILY_LIMIT:
        msg = build_limit_message(lang_code, "total")
        return {"answer": msg, "limit_reached": True}

    # 2) EÄŸer soru bariz keloid ile alakasÄ±zsa ve fast_route = websearch ise,
    #    websearch limitini kontrol et
    if fast_ds == "websearch" and stats["websearch"] >= WEBSEARCH_DAILY_LIMIT:
        msg = build_limit_message(lang_code, "websearch")
        return {"answer": msg, "limit_reached": True}

    # 3) Normal akÄ±ÅŸ: cevabÄ± Ã¼ret
    #    Burada precomputed_route GÃ–NDERMÄ°YORUZ ki smart_answer kendi router'Ä±nÄ± kullansÄ±n
    answer, meta = smart_answer(
        question,
        precomputed_route=None,
        lang_info=lang_info,
        user_name=user_name,
    )

    # GerÃ§ek datasource'u meta'dan al
    datasource = meta.get("datasource", fast_ds)

    # 4) SayaÃ§larÄ± cevaptan sonra artÄ±r
    stats["total"] += 1
    if datasource == "websearch":
        stats["websearch"] += 1

    return {
        "answer": answer,
        "meta": {
            "datasource": datasource,
            "source": meta.get("source"),
            "stage": meta.get("stage"),
            "limits": {
                "total_used": stats["total"],
                "total_limit": TOTAL_DAILY_LIMIT,
                "websearch_used": stats["websearch"],
                "websearch_limit": WEBSEARCH_DAILY_LIMIT,
            },
        },
    }



@app.post("/lead")
async def create_lead_endpoint(lead: LeadPayload):
    """
    Ä°letiÅŸim bilgilerini + (varsa) sohbet geÃ§miÅŸini alÄ±r,
    Airtable'a kaydeder.
    """
    try:
        airtable_resp = send_lead_to_airtable(lead)
        return {"status": "ok", "airtable": airtable_resp}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
